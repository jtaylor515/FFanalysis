{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vars import *\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('datasets/train.csv')\n",
    "test = pd.read_csv('datasets/test.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeff has added team name and opposing team name in the dataset. We're also interested in compiling information on a given player's salary, average points, max/min points, and point variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code will compile average player statistics for the training data\n",
    "# player_stats = data.groupby('PLAYER')['MISC FPTS'].agg(\n",
    "#     AVG_FPTS = 'mean',\n",
    "#     MIN_FPTS = 'min',\n",
    "#     MAX_FPTS = 'max',\n",
    "#     VAR_FPTS = 'std'\n",
    "# ).reset_index()\n",
    "\n",
    "# data = pd.merge(data, player_stats, on='PLAYER', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into quarterbacks and all other players (running backs, tight ends, and wide receivers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_train_data = train[train['POS'] == 'qb']\n",
    "qb_test_data = test[test['POS'] == 'qb']\n",
    "qb_train_data = qb_train_data.drop(columns=[\n",
    "    'POS RANK', 'POS', 'MISC G', 'MISC ROST', 'MISC FPTS/G', 'RECEIVING REC', 'RECEIVING TGT', 'RECEIVING YDS', 'RECEIVING Y/R',\n",
    "    'RECEIVING LG', 'RECEIVING 20+', 'RECEIVING TD', 'RUSHING Y/A', 'RUSHING LG',\n",
    "    'RUSHING 20+', 'DATE', 'YEAR', 'WEIGHT'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll want to store our response variable (fantasy points) separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_train_y = qb_train_data['MISC FPTS']\n",
    "qb_train_data = qb_train_data.drop(columns=['MISC FPTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PLAYER', 'PASSING CMP', 'PASSING ATT', 'PASSING PCT', 'PASSING YDS',\n",
       "       'PASSING Y/A', 'PASSING TD', 'PASSING INT', 'PASSING SACKS',\n",
       "       'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'WEEK', 'TEAM', 'OPP',\n",
       "       'AVG_FPTS', 'MIN_FPTS', 'MAX_FPTS', 'VAR_FPTS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qb_train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding for categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qb_data = pd.get_dummies(qb_data, columns=['TEAM', 'OPP', 'PLAYER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# change this to only use the train data\n",
    "scaler.fit_transform(qb_data)\n",
    "# scaler.transform(test data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA code\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(qb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make scree plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigenvalues\n",
    "eigen = pca.explained_variance_ratio_\n",
    "\n",
    "plt.plot(eigen)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.savefig('img/scree_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user input for the week number to predict\n",
    "num_week = int(input(\"Enter the week to predict: \"))\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "positions = [\"qb\", \"rb\", \"wr\", \"te\"]\n",
    "positions = [\"qb\"]\n",
    "\n",
    "\n",
    "for pos in positions:\n",
    "    # Load your dataset\n",
    "    data = pd.read_csv(\"datasets/weekly_scoring.csv\")\n",
    "    train = pd.read_csv(\"datasets/train.csv\")\n",
    "    test = pd.read_csv(\"datasets/test.csv\")\n",
    "\n",
    "    # Preprocessing\n",
    "    train = train[train['POS'] == pos]\n",
    "    test = test[test['POS'] == pos]\n",
    "    # weights = train['WEIGHT']\n",
    "    \n",
    "    if(pos == 'qb'):\n",
    "        data = data.drop(columns=['POS RANK', 'POS', 'MISC G', 'MISC ROST', 'MISC FPTS/G', 'RECEIVING REC', 'RECEIVING TGT', 'RECEIVING YDS', 'RECEIVING Y/R',\n",
    "        'RECEIVING LG', 'RECEIVING 20+', 'RECEIVING TD', 'RUSHING Y/A', 'RUSHING LG',\n",
    "        'RUSHING 20+', 'DATE', 'YEAR', 'WEIGHT', 'TEAM', 'OPP'])\n",
    "            # Define the list of variables to predict :)\n",
    "        var_list = ['PASSING CMP', 'PASSING ATT', 'PASSING PCT', 'PASSING YDS', 'PASSING Y/A', 'PASSING TD', 'PASSING INT',\n",
    "        'PASSING SACKS', 'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'MISC FL', 'MISC FPTS', 'WEEK']\n",
    "    if(pos == 'rb'):\n",
    "        # Define the list of variables to drop and predict\n",
    "        data = data.drop(columns=['POS RANK', 'POS', 'MISC G', 'MISC ROST', 'MISC FPTS/G', 'PASSING CMP', 'PASSING ATT', 'PASSING PCT', 'PASSING YDS', \n",
    "        'PASSING Y/A', 'PASSING TD', 'PASSING INT', 'RECEIVING LG', 'RECEIVING 20+',\n",
    "        'PASSING SACKS', 'YEAR', 'WEIGHT', 'DATE'])\n",
    "        var_list = ['RECEIVING REC', 'RECEIVING TGT', 'RECEIVING YDS', 'RECEIVING Y/R',\n",
    "        'RECEIVING TD', 'RUSHING Y/A', 'RUSHING LG',\n",
    "        'RUSHING 20+', 'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'MISC FL', 'MISC FPTS', 'WEEK']\n",
    "    if(pos == 'wr'):\n",
    "        # Define the list of variables to drop and predict\n",
    "        data = data.drop(columns=['POS RANK', 'POS', 'MISC G', 'MISC ROST', 'MISC FPTS/G', 'PASSING CMP', 'PASSING ATT', 'PASSING PCT', 'PASSING YDS', \n",
    "        'PASSING Y/A', 'PASSING TD', 'PASSING INT',\n",
    "        'PASSING SACKS', 'YEAR', 'WEIGHT', 'DATE', 'RUSHING Y/A', 'RUSHING LG', 'RUSHING 20+'])\n",
    "        var_list = ['RECEIVING REC', 'RECEIVING TGT', 'RECEIVING YDS', 'RECEIVING Y/R',\n",
    "        'RECEIVING TD', 'RECEIVING LG', 'RECEIVING 20+',\n",
    "        'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'MISC FL', 'MISC FPTS', 'WEEK']\n",
    "    if(pos == 'te'):\n",
    "        # Define the list of variables to drop and predict\n",
    "        data = data.drop(columns=['POS RANK', 'POS', 'MISC G', 'MISC ROST', 'MISC FPTS/G', 'PASSING CMP', 'PASSING ATT', 'PASSING PCT', 'PASSING YDS', \n",
    "        'PASSING Y/A', 'PASSING TD', 'PASSING INT',\n",
    "        'PASSING SACKS', 'YEAR', 'WEIGHT', 'DATE', 'RUSHING Y/A', 'RUSHING LG', 'RUSHING 20+'])\n",
    "        var_list = ['RECEIVING REC', 'RECEIVING TGT', 'RECEIVING YDS', 'RECEIVING Y/R',\n",
    "        'RECEIVING TD', 'RECEIVING LG', 'RECEIVING 20+',\n",
    "        'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'MISC FL', 'MISC FPTS', 'WEEK']\n",
    "\n",
    "    train = pd.get_dummies(train, columns=['PLAYER'], drop_first=True)\n",
    "    test = pd.get_dummies(test, columns=['PLAYER'], drop_first=True)\n",
    "\n",
    "    # Identify columns with missing values before imputation\n",
    "    columns_with_missing_tr = train.columns[train.isnull().any()].tolist()\n",
    "    columns_with_missing_te = test.columns[test.isnull().any()].tolist()\n",
    "\n",
    "    # Impute missing values with the mean of each column\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    train = pd.DataFrame(imputer.fit_transform(train), columns=data.columns)\n",
    "    test = pd.DataFrame(imputer.fit_transform(test), columns=data.columns)\n",
    "\n",
    "    # Separate the dataset into features (X) and the target variable (y)\n",
    "    XTrain = train.drop(var_list, axis=1)\n",
    "    XTest = test.drop(var_list, axis = 1)\n",
    "    yTrain = train['MISC FPTS']\n",
    "    yTest = test['MISC FPTS']\n",
    "\n",
    "    # Instantiate the Linear Regression model without hyperparameter tuning\n",
    "    lr_model = LinearRegression(fit_intercept=False)\n",
    "\n",
    "    # Fit the model directly without GridSearchCV\n",
    "    lr_model.fit(XTrain, yTrain)\n",
    "\n",
    "    print(lr_model.intercept_, lr_model.coef_, lr_model.score(XTrain, yTrain))\n",
    "\n",
    "    # # Get a list of unique player names after one-hot encoding\n",
    "    unique_players = data.columns\n",
    "\n",
    "    # Create a list of dictionaries to store the results\n",
    "    results_list = []\n",
    "\n",
    "    for player in unique_players:\n",
    "        # Create a DataFrame with all zeros\n",
    "        week6_data = pd.DataFrame(0, index=range(1), columns=X.columns)\n",
    "        # Set the corresponding player's column to 1 for prediction\n",
    "        week6_data[player] = 1\n",
    "        # Make a prediction for the player\n",
    "        misc_fpts_prediction = lr_model.predict(week6_data)\n",
    "        results_list.append({'Player': player, 'MISC FPTS': misc_fpts_prediction[0]})\n",
    "\n",
    "    # Convert the list of dictionaries into a DataFrame\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "\n",
    "    results_df = results_df.sort_values(by='MISC FPTS', ascending=False)\n",
    "\n",
    "    # # Save the results to a CSV file\n",
    "    file_name = f\"predictions/LRweek{num_week}{pos}unweighted.csv\"\n",
    "    results_df.to_csv(file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS334",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
