{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import subprocess\n",
    "import nbformat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape basic stat datasets from FantasyPros.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape overall scoring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r0/wxyx40j52h9551yrrxdd77rh0000gs/T/ipykernel_63955/626880590.py:29: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table), header=[0, 1])[0]\n",
      "/var/folders/r0/wxyx40j52h9551yrrxdd77rh0000gs/T/ipykernel_63955/626880590.py:29: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table), header=[0, 1])[0]\n",
      "/var/folders/r0/wxyx40j52h9551yrrxdd77rh0000gs/T/ipykernel_63955/626880590.py:29: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table), header=[0, 1])[0]\n",
      "/var/folders/r0/wxyx40j52h9551yrrxdd77rh0000gs/T/ipykernel_63955/626880590.py:29: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table), header=[0, 1])[0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List of URLs to scrape for fantasy stats\n",
    "urls = [\n",
    "    'https://www.fantasypros.com/nfl/stats/qb.php?scoring=HALF&roster=y',\n",
    "    'https://www.fantasypros.com/nfl/stats/rb.php?scoring=HALF&roster=y',\n",
    "    'https://www.fantasypros.com/nfl/stats/wr.php?scoring=HALF&roster=y',\n",
    "    'https://www.fantasypros.com/nfl/stats/te.php?scoring=HALF&roster=y'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "for url in urls:\n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find the table on the page\n",
    "        table = soup.find('table')\n",
    "\n",
    "        # Read the table into a Pandas DataFrame\n",
    "        df = pd.read_html(str(table), header=[0, 1])[0]\n",
    "        \n",
    "        # Add a \"LOC\" column to the DataFrame\n",
    "        loc = url.split('/')[-1][:2]\n",
    "        df[(\"LOC\", \"POS\")] = loc\n",
    "\n",
    "        data_frames.append(df)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data from {url}\")\n",
    "\n",
    "# Merge all DataFrames into one based on the first and second row headers\n",
    "merged_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Combine values in column names (headers) and row 0\n",
    "merged_df.columns = merged_df.columns.map(' '.join)\n",
    "\n",
    "# Reset the index\n",
    "merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rename columns as specified\n",
    "merged_df = merged_df.rename(columns={\"Unnamed: 0_level_0 Rank\": \"POS RANK\", \"Unnamed: 1_level_0 Player\": \"PLAYER\", \"LOC POS\": \"POS\"})\n",
    "\n",
    "merged_df.to_csv('datasets/overall_scoring.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape snap counts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r0/wxyx40j52h9551yrrxdd77rh0000gs/T/ipykernel_63955/3466229442.py:28: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table), header=[0])[0]\n",
      "/var/folders/r0/wxyx40j52h9551yrrxdd77rh0000gs/T/ipykernel_63955/3466229442.py:28: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table), header=[0])[0]\n",
      "/var/folders/r0/wxyx40j52h9551yrrxdd77rh0000gs/T/ipykernel_63955/3466229442.py:28: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table), header=[0])[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>TTL</th>\n",
       "      <th>AVG</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isiah Pacheco</td>\n",
       "      <td>KC</td>\n",
       "      <td>48%</td>\n",
       "      <td>51%</td>\n",
       "      <td>42%</td>\n",
       "      <td>60%</td>\n",
       "      <td>59%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178</td>\n",
       "      <td>52%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clyde Edwards-Helaire</td>\n",
       "      <td>KC</td>\n",
       "      <td>22%</td>\n",
       "      <td>16%</td>\n",
       "      <td>30%</td>\n",
       "      <td>9%</td>\n",
       "      <td>14%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>18%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jerick McKinnon</td>\n",
       "      <td>KC</td>\n",
       "      <td>31%</td>\n",
       "      <td>33%</td>\n",
       "      <td>29%</td>\n",
       "      <td>31%</td>\n",
       "      <td>27%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104</td>\n",
       "      <td>30%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jahmyr Gibbs</td>\n",
       "      <td>DET</td>\n",
       "      <td>27%</td>\n",
       "      <td>48%</td>\n",
       "      <td>60%</td>\n",
       "      <td>37%</td>\n",
       "      <td>0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121</td>\n",
       "      <td>43%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Montgomery</td>\n",
       "      <td>DET</td>\n",
       "      <td>79%</td>\n",
       "      <td>45%</td>\n",
       "      <td>0%</td>\n",
       "      <td>71%</td>\n",
       "      <td>75%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183</td>\n",
       "      <td>68%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gus Edwards</td>\n",
       "      <td>BAL</td>\n",
       "      <td>23%</td>\n",
       "      <td>43%</td>\n",
       "      <td>44%</td>\n",
       "      <td>69%</td>\n",
       "      <td>43%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149</td>\n",
       "      <td>44%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>J.K. Dobbins</td>\n",
       "      <td>BAL</td>\n",
       "      <td>47%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>47%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Justice Hill</td>\n",
       "      <td>BAL</td>\n",
       "      <td>30%</td>\n",
       "      <td>57%</td>\n",
       "      <td>0%</td>\n",
       "      <td>12%</td>\n",
       "      <td>56%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108</td>\n",
       "      <td>40%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dameon Pierce</td>\n",
       "      <td>HOU</td>\n",
       "      <td>47%</td>\n",
       "      <td>45%</td>\n",
       "      <td>54%</td>\n",
       "      <td>59%</td>\n",
       "      <td>59%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180</td>\n",
       "      <td>52%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Devin Singletary</td>\n",
       "      <td>HOU</td>\n",
       "      <td>21%</td>\n",
       "      <td>36%</td>\n",
       "      <td>39%</td>\n",
       "      <td>35%</td>\n",
       "      <td>29%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110</td>\n",
       "      <td>32%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player Team    1    2    3    4    5   6   7   8  ...  12  \\\n",
       "0          Isiah Pacheco   KC  48%  51%  42%  60%  59% NaN NaN NaN  ... NaN   \n",
       "1  Clyde Edwards-Helaire   KC  22%  16%  30%   9%  14% NaN NaN NaN  ... NaN   \n",
       "2        Jerick McKinnon   KC  31%  33%  29%  31%  27% NaN NaN NaN  ... NaN   \n",
       "3           Jahmyr Gibbs  DET  27%  48%  60%  37%   0% NaN NaN NaN  ... NaN   \n",
       "4       David Montgomery  DET  79%  45%   0%  71%  75% NaN NaN NaN  ... NaN   \n",
       "5            Gus Edwards  BAL  23%  43%  44%  69%  43% NaN NaN NaN  ... NaN   \n",
       "6           J.K. Dobbins  BAL  47%   0%   0%   0%   0% NaN NaN NaN  ... NaN   \n",
       "7           Justice Hill  BAL  30%  57%   0%  12%  56% NaN NaN NaN  ... NaN   \n",
       "8          Dameon Pierce  HOU  47%  45%  54%  59%  59% NaN NaN NaN  ... NaN   \n",
       "9       Devin Singletary  HOU  21%  36%  39%  35%  29% NaN NaN NaN  ... NaN   \n",
       "\n",
       "   13  14  15  16  17  18  TTL  AVG  POS  \n",
       "0 NaN NaN NaN NaN NaN NaN  178  52%   rb  \n",
       "1 NaN NaN NaN NaN NaN NaN   63  18%   rb  \n",
       "2 NaN NaN NaN NaN NaN NaN  104  30%   rb  \n",
       "3 NaN NaN NaN NaN NaN NaN  121  43%   rb  \n",
       "4 NaN NaN NaN NaN NaN NaN  183  68%   rb  \n",
       "5 NaN NaN NaN NaN NaN NaN  149  44%   rb  \n",
       "6 NaN NaN NaN NaN NaN NaN   30  47%   rb  \n",
       "7 NaN NaN NaN NaN NaN NaN  108  40%   rb  \n",
       "8 NaN NaN NaN NaN NaN NaN  180  52%   rb  \n",
       "9 NaN NaN NaN NaN NaN NaN  110  32%   rb  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List of URLs to scrape for snap counts\n",
    "snap_count_urls = [\n",
    "    'https://www.fantasypros.com/nfl/reports/snap-counts/rb.php?show=perc',\n",
    "    'https://www.fantasypros.com/nfl/reports/snap-counts/wr.php?show=perc',\n",
    "    'https://www.fantasypros.com/nfl/reports/snap-counts/te.php?show=perc'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store DataFrames for snap counts\n",
    "snap_count_data_frames = []\n",
    "\n",
    "for url in snap_count_urls:\n",
    "    # Send an HTTP GET request to the URL for snap counts\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find the table on the page\n",
    "        table = soup.find('table')\n",
    "\n",
    "        # Read the table into a Pandas DataFrame\n",
    "        df = pd.read_html(str(table), header=[0])[0]\n",
    "        \n",
    "        # Add a \"POS\" column to the DataFrame for snap counts\n",
    "        pos = url.split('/')[-1][:2]\n",
    "        df[(\"POS\")] = pos\n",
    "\n",
    "        snap_count_data_frames.append(df)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data from {url} (snap counts)\")\n",
    "\n",
    "# Concatenate (append) all DataFrames for snap counts\n",
    "snap_count_merged_df = pd.concat(snap_count_data_frames, ignore_index=True)\n",
    "\n",
    "# If you want to save the data to a CSV file, you can do it like this:\n",
    "snap_count_merged_df.to_csv('datasets/snap_counts.csv', index=False)\n",
    "\n",
    "snap_count_merged_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push updated data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 70f8cf6] Update files\n",
      " 2 files changed, 1272 insertions(+)\n",
      " create mode 100644 datasets/overall_scoring.csv\n",
      " create mode 100644 datasets/snap_counts.csv\n",
      "File datasets/ successfully pushed to the repository.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/jtaylor515/FFanalysis.git\n",
      "   9648ec5..70f8cf6  main -> main\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# List of file paths to push\n",
    "file_paths = [\"datasets/\"]\n",
    "\n",
    "# Specify the GitHub repository URL\n",
    "repo_url = \"https://github.com/jtaylor515/FFanalysis.git\"\n",
    "\n",
    "# Specify your commit message\n",
    "commit_message = \"Update files\"\n",
    "\n",
    "# Git commands to add, commit, and push each file in the list\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        subprocess.run([\"git\", \"add\", file_path])\n",
    "        subprocess.run([\"git\", \"commit\", \"-m\", commit_message])\n",
    "        subprocess.run([\"git\", \"push\", repo_url])\n",
    "        print(f\"File {file_path} successfully pushed to the repository.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
