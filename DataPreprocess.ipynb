{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\jefft\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: importlib in c:\\users\\jefft\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml\n",
    "%pip install importlib\n",
    "import importlib\n",
    "\n",
    "# Check if the package is installed, and if not, install it\n",
    "def install_package(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.check_call(['pip', 'install', package_name])\n",
    "\n",
    "# Check and install required packages\n",
    "required_packages = ['pandas', 'requests', 'beautifulsoup4', 'nbformat', 'io']\n",
    "\n",
    "for package in required_packages:\n",
    "    install_package(package)\n",
    "\n",
    "# Now you can safely import the packages\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nbformat\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape basic stat datasets from FantasyPros.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape overall scoring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jefft\\AppData\\Local\\Temp\\ipykernel_5168\\626880590.py:29: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table), header=[0, 1])[0]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'lxml'.  Use pip or conda to install lxml.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\compat\\_optional.py:132\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 132\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(name)\n\u001b[0;32m    133\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1126\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lxml'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jefft\\Desktop\\FF\\FFanalysis\\DataPreprocess.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jefft/Desktop/FF/FFanalysis/DataPreprocess.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m table \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jefft/Desktop/FF/FFanalysis/DataPreprocess.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Read the table into a Pandas DataFrame\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jefft/Desktop/FF/FFanalysis/DataPreprocess.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_html(\u001b[39mstr\u001b[39;49m(table), header\u001b[39m=\u001b[39;49m[\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m])[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jefft/Desktop/FF/FFanalysis/DataPreprocess.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Add a \"LOC\" column to the DataFrame\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jefft/Desktop/FF/FFanalysis/DataPreprocess.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m loc \u001b[39m=\u001b[39m url\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][:\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:1245\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(io, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[0;32m   1230\u001b[0m     [\n\u001b[0;32m   1231\u001b[0m         is_file_like(io),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1235\u001b[0m     ]\n\u001b[0;32m   1236\u001b[0m ):\n\u001b[0;32m   1237\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing literal html to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mread_html\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. To read from a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1242\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1243\u001b[0m     )\n\u001b[1;32m-> 1245\u001b[0m \u001b[39mreturn\u001b[39;00m _parse(\n\u001b[0;32m   1246\u001b[0m     flavor\u001b[39m=\u001b[39;49mflavor,\n\u001b[0;32m   1247\u001b[0m     io\u001b[39m=\u001b[39;49mio,\n\u001b[0;32m   1248\u001b[0m     match\u001b[39m=\u001b[39;49mmatch,\n\u001b[0;32m   1249\u001b[0m     header\u001b[39m=\u001b[39;49mheader,\n\u001b[0;32m   1250\u001b[0m     index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m   1251\u001b[0m     skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[0;32m   1252\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m   1253\u001b[0m     thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[0;32m   1254\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1255\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   1256\u001b[0m     decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[0;32m   1257\u001b[0m     converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[0;32m   1258\u001b[0m     na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[0;32m   1259\u001b[0m     keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[0;32m   1260\u001b[0m     displayed_only\u001b[39m=\u001b[39;49mdisplayed_only,\n\u001b[0;32m   1261\u001b[0m     extract_links\u001b[39m=\u001b[39;49mextract_links,\n\u001b[0;32m   1262\u001b[0m     dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[0;32m   1263\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   1264\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:976\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m retained \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[39mfor\u001b[39;00m flav \u001b[39min\u001b[39;00m flavor:\n\u001b[1;32m--> 976\u001b[0m     parser \u001b[39m=\u001b[39m _parser_dispatch(flav)\n\u001b[0;32m    977\u001b[0m     p \u001b[39m=\u001b[39m parser(\n\u001b[0;32m    978\u001b[0m         io,\n\u001b[0;32m    979\u001b[0m         compiled_match,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    984\u001b[0m         storage_options,\n\u001b[0;32m    985\u001b[0m     )\n\u001b[0;32m    987\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\html.py:923\u001b[0m, in \u001b[0;36m_parser_dispatch\u001b[1;34m(flavor)\u001b[0m\n\u001b[0;32m    921\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mbs4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    922\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 923\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mlxml.etree\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    924\u001b[0m \u001b[39mreturn\u001b[39;00m _valid_parsers[flavor]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\compat\\_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 135\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[0;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[39m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'lxml'.  Use pip or conda to install lxml."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List of URLs to scrape for fantasy stats\n",
    "urls = [\n",
    "    'https://www.fantasypros.com/nfl/stats/qb.php?scoring=HALF&roster=y',\n",
    "    'https://www.fantasypros.com/nfl/stats/rb.php?scoring=HALF&roster=y',\n",
    "    'https://www.fantasypros.com/nfl/stats/wr.php?scoring=HALF&roster=y',\n",
    "    'https://www.fantasypros.com/nfl/stats/te.php?scoring=HALF&roster=y'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "for url in urls:\n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find the table on the page\n",
    "        table = soup.find('table')\n",
    "\n",
    "        # Read the table into a Pandas DataFrame\n",
    "        df = pd.read_html(str(table), header=[0, 1])[0]\n",
    "        \n",
    "        # Add a \"LOC\" column to the DataFrame\n",
    "        loc = url.split('/')[-1][:2]\n",
    "        df[(\"LOC\", \"POS\")] = loc\n",
    "\n",
    "        data_frames.append(df)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data from {url}\")\n",
    "\n",
    "# Merge all DataFrames into one based on the first and second row headers\n",
    "merged_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Combine values in column names (headers) and row 0\n",
    "merged_df.columns = merged_df.columns.map(' '.join)\n",
    "\n",
    "# Reset the index\n",
    "merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rename columns as specified\n",
    "merged_df = merged_df.rename(columns={\"Unnamed: 0_level_0 Rank\": \"POS RANK\", \"Unnamed: 1_level_0 Player\": \"PLAYER\", \"LOC POS\": \"POS\"})\n",
    "\n",
    "merged_df.to_csv('datasets/overall_scoring.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape snap counts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r0/wxyx40j52h9551yrrxdd77rh0000gs/T/ipykernel_63955/3466229442.py:28: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table), header=[0])[0]\n",
      "/var/folders/r0/wxyx40j52h9551yrrxdd77rh0000gs/T/ipykernel_63955/3466229442.py:28: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table), header=[0])[0]\n",
      "/var/folders/r0/wxyx40j52h9551yrrxdd77rh0000gs/T/ipykernel_63955/3466229442.py:28: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table), header=[0])[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>TTL</th>\n",
       "      <th>AVG</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isiah Pacheco</td>\n",
       "      <td>KC</td>\n",
       "      <td>48%</td>\n",
       "      <td>51%</td>\n",
       "      <td>42%</td>\n",
       "      <td>60%</td>\n",
       "      <td>59%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178</td>\n",
       "      <td>52%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clyde Edwards-Helaire</td>\n",
       "      <td>KC</td>\n",
       "      <td>22%</td>\n",
       "      <td>16%</td>\n",
       "      <td>30%</td>\n",
       "      <td>9%</td>\n",
       "      <td>14%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>18%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jerick McKinnon</td>\n",
       "      <td>KC</td>\n",
       "      <td>31%</td>\n",
       "      <td>33%</td>\n",
       "      <td>29%</td>\n",
       "      <td>31%</td>\n",
       "      <td>27%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104</td>\n",
       "      <td>30%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jahmyr Gibbs</td>\n",
       "      <td>DET</td>\n",
       "      <td>27%</td>\n",
       "      <td>48%</td>\n",
       "      <td>60%</td>\n",
       "      <td>37%</td>\n",
       "      <td>0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121</td>\n",
       "      <td>43%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Montgomery</td>\n",
       "      <td>DET</td>\n",
       "      <td>79%</td>\n",
       "      <td>45%</td>\n",
       "      <td>0%</td>\n",
       "      <td>71%</td>\n",
       "      <td>75%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183</td>\n",
       "      <td>68%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gus Edwards</td>\n",
       "      <td>BAL</td>\n",
       "      <td>23%</td>\n",
       "      <td>43%</td>\n",
       "      <td>44%</td>\n",
       "      <td>69%</td>\n",
       "      <td>43%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149</td>\n",
       "      <td>44%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>J.K. Dobbins</td>\n",
       "      <td>BAL</td>\n",
       "      <td>47%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>47%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Justice Hill</td>\n",
       "      <td>BAL</td>\n",
       "      <td>30%</td>\n",
       "      <td>57%</td>\n",
       "      <td>0%</td>\n",
       "      <td>12%</td>\n",
       "      <td>56%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108</td>\n",
       "      <td>40%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dameon Pierce</td>\n",
       "      <td>HOU</td>\n",
       "      <td>47%</td>\n",
       "      <td>45%</td>\n",
       "      <td>54%</td>\n",
       "      <td>59%</td>\n",
       "      <td>59%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180</td>\n",
       "      <td>52%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Devin Singletary</td>\n",
       "      <td>HOU</td>\n",
       "      <td>21%</td>\n",
       "      <td>36%</td>\n",
       "      <td>39%</td>\n",
       "      <td>35%</td>\n",
       "      <td>29%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110</td>\n",
       "      <td>32%</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player Team    1    2    3    4    5   6   7   8  ...  12  \\\n",
       "0          Isiah Pacheco   KC  48%  51%  42%  60%  59% NaN NaN NaN  ... NaN   \n",
       "1  Clyde Edwards-Helaire   KC  22%  16%  30%   9%  14% NaN NaN NaN  ... NaN   \n",
       "2        Jerick McKinnon   KC  31%  33%  29%  31%  27% NaN NaN NaN  ... NaN   \n",
       "3           Jahmyr Gibbs  DET  27%  48%  60%  37%   0% NaN NaN NaN  ... NaN   \n",
       "4       David Montgomery  DET  79%  45%   0%  71%  75% NaN NaN NaN  ... NaN   \n",
       "5            Gus Edwards  BAL  23%  43%  44%  69%  43% NaN NaN NaN  ... NaN   \n",
       "6           J.K. Dobbins  BAL  47%   0%   0%   0%   0% NaN NaN NaN  ... NaN   \n",
       "7           Justice Hill  BAL  30%  57%   0%  12%  56% NaN NaN NaN  ... NaN   \n",
       "8          Dameon Pierce  HOU  47%  45%  54%  59%  59% NaN NaN NaN  ... NaN   \n",
       "9       Devin Singletary  HOU  21%  36%  39%  35%  29% NaN NaN NaN  ... NaN   \n",
       "\n",
       "   13  14  15  16  17  18  TTL  AVG  POS  \n",
       "0 NaN NaN NaN NaN NaN NaN  178  52%   rb  \n",
       "1 NaN NaN NaN NaN NaN NaN   63  18%   rb  \n",
       "2 NaN NaN NaN NaN NaN NaN  104  30%   rb  \n",
       "3 NaN NaN NaN NaN NaN NaN  121  43%   rb  \n",
       "4 NaN NaN NaN NaN NaN NaN  183  68%   rb  \n",
       "5 NaN NaN NaN NaN NaN NaN  149  44%   rb  \n",
       "6 NaN NaN NaN NaN NaN NaN   30  47%   rb  \n",
       "7 NaN NaN NaN NaN NaN NaN  108  40%   rb  \n",
       "8 NaN NaN NaN NaN NaN NaN  180  52%   rb  \n",
       "9 NaN NaN NaN NaN NaN NaN  110  32%   rb  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List of URLs to scrape for snap counts\n",
    "snap_count_urls = [\n",
    "    'https://www.fantasypros.com/nfl/reports/snap-counts/rb.php?show=perc',\n",
    "    'https://www.fantasypros.com/nfl/reports/snap-counts/wr.php?show=perc',\n",
    "    'https://www.fantasypros.com/nfl/reports/snap-counts/te.php?show=perc'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store DataFrames for snap counts\n",
    "snap_count_data_frames = []\n",
    "\n",
    "for url in snap_count_urls:\n",
    "    # Send an HTTP GET request to the URL for snap counts\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find the table on the page\n",
    "        table = soup.find('table')\n",
    "\n",
    "        # Read the table into a Pandas DataFrame\n",
    "        df = pd.read_html(str(table), header=[0])[0]\n",
    "        \n",
    "        # Add a \"POS\" column to the DataFrame for snap counts\n",
    "        pos = url.split('/')[-1][:2]\n",
    "        df[(\"POS\")] = pos\n",
    "\n",
    "        snap_count_data_frames.append(df)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data from {url} (snap counts)\")\n",
    "\n",
    "# Concatenate (append) all DataFrames for snap counts\n",
    "snap_count_merged_df = pd.concat(snap_count_data_frames, ignore_index=True)\n",
    "\n",
    "# If you want to save the data to a CSV file, you can do it like this:\n",
    "snap_count_merged_df.to_csv('datasets/snap_counts.csv', index=False)\n",
    "\n",
    "snap_count_merged_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push updated data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 70f8cf6] Update files\n",
      " 2 files changed, 1272 insertions(+)\n",
      " create mode 100644 datasets/overall_scoring.csv\n",
      " create mode 100644 datasets/snap_counts.csv\n",
      "File datasets/ successfully pushed to the repository.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/jtaylor515/FFanalysis.git\n",
      "   9648ec5..70f8cf6  main -> main\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# List of file paths to push\n",
    "file_paths = [\"datasets/\"]\n",
    "\n",
    "# Specify the GitHub repository URL\n",
    "repo_url = \"https://github.com/jtaylor515/FFanalysis.git\"\n",
    "\n",
    "# Specify your commit message\n",
    "commit_message = \"Update files\"\n",
    "\n",
    "# Git commands to add, commit, and push each file in the list\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        subprocess.run([\"git\", \"add\", file_path])\n",
    "        subprocess.run([\"git\", \"commit\", \"-m\", commit_message])\n",
    "        subprocess.run([\"git\", \"push\", repo_url])\n",
    "        print(f\"File {file_path} successfully pushed to the repository.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape weekly scoring data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate URLs to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user input for the number of URLs to generate\n",
    "num_urls = int(input(\"Enter the current week: \"))\n",
    "\n",
    "# Define the base URL and the page options\n",
    "base_url = \"https://www.fantasypros.com/nfl/stats/\"\n",
    "\n",
    "# List of page options\n",
    "pages = ['qb.php', 'wr.php', 'rb.php', 'te.php']\n",
    "\n",
    "# Initialize the list to store the generated URLs\n",
    "urls = []\n",
    "\n",
    "# Generate URLs based on user input\n",
    "for page in pages:\n",
    "    for week in range(1, num_urls + 1):\n",
    "        url = f\"{base_url}{page}?range=week&week={week}\"\n",
    "        urls.append(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS RANK</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>PASSING CMP</th>\n",
       "      <th>PASSING ATT</th>\n",
       "      <th>PASSING PCT</th>\n",
       "      <th>PASSING YDS</th>\n",
       "      <th>PASSING Y/A</th>\n",
       "      <th>PASSING TD</th>\n",
       "      <th>PASSING INT</th>\n",
       "      <th>PASSING SACKS</th>\n",
       "      <th>...</th>\n",
       "      <th>RECEIVING REC</th>\n",
       "      <th>RECEIVING TGT</th>\n",
       "      <th>RECEIVING YDS</th>\n",
       "      <th>RECEIVING Y/R</th>\n",
       "      <th>RECEIVING LG</th>\n",
       "      <th>RECEIVING 20+</th>\n",
       "      <th>RECEIVING TD</th>\n",
       "      <th>RUSHING Y/A</th>\n",
       "      <th>RUSHING LG</th>\n",
       "      <th>RUSHING 20+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Tua Tagovailoa (MIA)</td>\n",
       "      <td>28.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>62.2</td>\n",
       "      <td>466.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mac Jones (NE)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>316.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jordan Love (GB)</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>55.6</td>\n",
       "      <td>245.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Anthony Richardson (IND)</td>\n",
       "      <td>24.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>64.9</td>\n",
       "      <td>223.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Deshaun Watson (CLE)</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>55.2</td>\n",
       "      <td>154.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Justin Herbert (LAC)</td>\n",
       "      <td>23.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>69.7</td>\n",
       "      <td>229.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Patrick Mahomes II (KC)</td>\n",
       "      <td>21.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>53.8</td>\n",
       "      <td>226.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Trevor Lawrence (JAC)</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Kirk Cousins (MIN)</td>\n",
       "      <td>33.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Brock Purdy (SF)</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>65.5</td>\n",
       "      <td>220.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   POS RANK                    PLAYER  PASSING CMP  PASSING ATT  PASSING PCT  \\\n",
       "0         1      Tua Tagovailoa (MIA)         28.0         45.0         62.2   \n",
       "1         2            Mac Jones (NE)         35.0         54.0         64.8   \n",
       "2         3          Jordan Love (GB)         15.0         27.0         55.6   \n",
       "3         4  Anthony Richardson (IND)         24.0         37.0         64.9   \n",
       "4         5      Deshaun Watson (CLE)         16.0         29.0         55.2   \n",
       "5         6      Justin Herbert (LAC)         23.0         33.0         69.7   \n",
       "6         7   Patrick Mahomes II (KC)         21.0         39.0         53.8   \n",
       "7         8     Trevor Lawrence (JAC)         24.0         32.0         75.0   \n",
       "8         9        Kirk Cousins (MIN)         33.0         44.0         75.0   \n",
       "9        10          Brock Purdy (SF)         19.0         29.0         65.5   \n",
       "\n",
       "   PASSING YDS  PASSING Y/A  PASSING TD  PASSING INT  PASSING SACKS  ...  \\\n",
       "0        466.0         10.4         3.0          1.0            0.0  ...   \n",
       "1        316.0          5.9         3.0          1.0            2.0  ...   \n",
       "2        245.0          9.1         3.0          0.0            1.0  ...   \n",
       "3        223.0          6.0         1.0          1.0            4.0  ...   \n",
       "4        154.0          5.3         1.0          1.0            3.0  ...   \n",
       "5        229.0          6.9         1.0          0.0            3.0  ...   \n",
       "6        226.0          5.8         2.0          1.0            0.0  ...   \n",
       "7        241.0          7.5         2.0          1.0            2.0  ...   \n",
       "8        344.0          7.8         2.0          1.0            2.0  ...   \n",
       "9        220.0          7.6         2.0          0.0            3.0  ...   \n",
       "\n",
       "   RECEIVING REC  RECEIVING TGT  RECEIVING YDS  RECEIVING Y/R  RECEIVING LG  \\\n",
       "0            NaN            NaN            NaN            NaN           NaN   \n",
       "1            NaN            NaN            NaN            NaN           NaN   \n",
       "2            NaN            NaN            NaN            NaN           NaN   \n",
       "3            NaN            NaN            NaN            NaN           NaN   \n",
       "4            NaN            NaN            NaN            NaN           NaN   \n",
       "5            NaN            NaN            NaN            NaN           NaN   \n",
       "6            NaN            NaN            NaN            NaN           NaN   \n",
       "7            NaN            NaN            NaN            NaN           NaN   \n",
       "8            NaN            NaN            NaN            NaN           NaN   \n",
       "9            NaN            NaN            NaN            NaN           NaN   \n",
       "\n",
       "   RECEIVING 20+  RECEIVING TD RUSHING Y/A RUSHING LG  RUSHING 20+  \n",
       "0            NaN           NaN         NaN        NaN          NaN  \n",
       "1            NaN           NaN         NaN        NaN          NaN  \n",
       "2            NaN           NaN         NaN        NaN          NaN  \n",
       "3            NaN           NaN         NaN        NaN          NaN  \n",
       "4            NaN           NaN         NaN        NaN          NaN  \n",
       "5            NaN           NaN         NaN        NaN          NaN  \n",
       "6            NaN           NaN         NaN        NaN          NaN  \n",
       "7            NaN           NaN         NaN        NaN          NaN  \n",
       "8            NaN           NaN         NaN        NaN          NaN  \n",
       "9            NaN           NaN         NaN        NaN          NaN  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store the data\n",
    "final_dataset = pd.DataFrame()\n",
    "\n",
    "# Iterate through the URLs\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Assuming the data is in a table, you may need to adjust the code based on the actual structure\n",
    "        table = soup.find('table')\n",
    "\n",
    "        # Use io.StringIO to wrap the HTML content\n",
    "        table_string = str(table)\n",
    "        table_io = StringIO(table_string)\n",
    "        \n",
    "        # Read the table into a DataFrame\n",
    "        df = pd.read_html(table_io)[0]\n",
    "\n",
    "        # Add a \"LOC\" column to the DataFrame\n",
    "        loc = url.split('/')[-1][:2]\n",
    "        df[(\"LOC\", \"POS\")] = loc\n",
    "        \n",
    "        # Extract week value from the URL\n",
    "        week_value = int(url.split('week=')[1])\n",
    "        \n",
    "        # Add a new 'Week' column with the week value\n",
    "        df['WEEK'] = week_value\n",
    "        \n",
    "        # Concatenate the DataFrame to the final dataset\n",
    "        final_dataset = pd.concat([final_dataset, df], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from URL: {url}\")\n",
    "\n",
    "# Now, final_dataset contains the combined data with a 'Week' column\n",
    "# final_dataset.head(10)\n",
    "\n",
    "# Combine values in column names (headers) and row 0\n",
    "final_dataset.columns = final_dataset.columns.map(' '.join)\n",
    "\n",
    "# Reset the index\n",
    "final_dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rename columns as specified\n",
    "final_dataset = final_dataset.rename(columns={\"Unnamed: 0_level_0 Rank\": \"POS RANK\", \"Unnamed: 1_level_0 Player\": \"PLAYER\", \"LOC POS\": \"POS\"})\n",
    "\n",
    "final_dataset.to_csv('datasets/weekly_scoring.csv', index=False)\n",
    "\n",
    "final_dataset.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
