{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'estimator' parameter of SequentialFeatureSelector must be an object implementing 'fit'. Got <class 'keras.src.layers.rnn.lstm.LSTM'> instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/jeffreytaylor/Desktop/FFproject/FFanalysis/optimal_lstm.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeffreytaylor/Desktop/FFproject/FFanalysis/optimal_lstm.ipynb#W0sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39m# Use SequentialFeatureSelector as a feature selection step\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeffreytaylor/Desktop/FFproject/FFanalysis/optimal_lstm.ipynb#W0sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m sfs \u001b[39m=\u001b[39m SequentialFeatureSelector(estimator\u001b[39m=\u001b[39mLSTM, direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbackward\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jeffreytaylor/Desktop/FFproject/FFanalysis/optimal_lstm.ipynb#W0sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m X_train_selected \u001b[39m=\u001b[39m sfs\u001b[39m.\u001b[39mfit_transform(X_train, Y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeffreytaylor/Desktop/FFproject/FFanalysis/optimal_lstm.ipynb#W0sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m model\u001b[39m.\u001b[39madd(LSTM(units\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, input_shape\u001b[39m=\u001b[39m(X_train_selected\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeffreytaylor/Desktop/FFproject/FFanalysis/optimal_lstm.ipynb#W0sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(units\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))  \u001b[39m# Assuming you are predicting a single value (MISC FPTS)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1144\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m partial_fit_and_fitted \u001b[39m=\u001b[39m (\n\u001b[1;32m   1140\u001b[0m     fit_method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpartial_fit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1141\u001b[0m )\n\u001b[1;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m global_skip_validation \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[1;32m   1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:637\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    630\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \n\u001b[1;32m    632\u001b[0m \u001b[39m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     validate_parameter_constraints(\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parameter_constraints,\n\u001b[1;32m    639\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m    640\u001b[0m         caller_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m,\n\u001b[1;32m    641\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'estimator' parameter of SequentialFeatureSelector must be an object implementing 'fit'. Got <class 'keras.src.layers.rnn.lstm.LSTM'> instead."
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "# Assuming 'features' is the complete list of features in your dataset\n",
    "all_features = ['PASSING CMP', 'PASSING ATT', 'PASSING PCT', 'PASSING YDS', 'PASSING Y/A', 'PASSING TD', 'PASSING INT',\n",
    "                'PASSING SACKS', 'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'RECEIVING REC', 'RECEIVING TGT', 'RECEIVING YDS',\n",
    "                'RECEIVING Y/R', 'RECEIVING TD', 'RECEIVING LG', 'RECEIVING 20+', 'MISC FL', 'WEEK', 'AVG_FPTS', 'MAX_FPTS',\n",
    "                'MIN_FPTS', 'VAR_FPTS', 'MISC FPTS']\n",
    "\n",
    "# Define positions\n",
    "positions = [\"qb\", \"rb\", \"wr\", \"te\"]\n",
    "\n",
    "# Dictionary to store the optimal features for each position\n",
    "optimal_features_dict = {}\n",
    "\n",
    "# Iterate over positions\n",
    "for pos in positions:\n",
    "    data = pd.read_csv(\"datasets/weekly_scoring.csv\")\n",
    "\n",
    "    # Filter data for the current position\n",
    "    data_pos = data[data['POS'] == pos]\n",
    "\n",
    "    # Filter out rows with zero 'MISC FPTS'\n",
    "    data_pos = data_pos[data_pos['MISC FPTS'] != 0]\n",
    "\n",
    "    # Initialize variables to store best features and performance\n",
    "    best_features = None\n",
    "    best_performance = float('inf')  # You may use a different metric depending on your goal\n",
    "\n",
    "    # Generate all combinations of features\n",
    "    for r in range(1, len(all_features) + 1):\n",
    "        feature_combinations = list(itertools.combinations(all_features, r))\n",
    "\n",
    "        # Iterate over feature combinations\n",
    "        for features_to_predict in feature_combinations:\n",
    "            # Convert the combination to a list\n",
    "            features_to_predict = list(features_to_predict)\n",
    "\n",
    "            # Update columns_to_predict based on the current feature combination\n",
    "            columns_to_predict = features_to_predict + ['MISC FPTS']\n",
    "\n",
    "            # Sort the data by the date column\n",
    "            date_column = \"CONTINUOUS_DATE\"\n",
    "            data_pos[date_column] = pd.to_datetime(data_pos[date_column])\n",
    "            data_pos = data_pos.sort_values(by=date_column)\n",
    "\n",
    "            # Extract the relevant columns for training\n",
    "            training_data = data_pos[columns_to_predict].values\n",
    "\n",
    "            # Impute missing values for training_data\n",
    "            imputer = SimpleImputer(strategy='mean')  # You can change the strategy as needed\n",
    "            training_data = imputer.fit_transform(training_data)\n",
    "\n",
    "            # Normalize the data using Min-Max scaling\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            training_data_scaled = scaler.fit_transform(training_data)\n",
    "\n",
    "            # Define a function to create LSTM datasets\n",
    "            def create_lstm_dataset(dataset, look_back=1):\n",
    "                X, Y = [], []\n",
    "                for i in range(len(dataset) - look_back):\n",
    "                    X.append(dataset[i:(i + look_back)])\n",
    "                    Y.append(dataset[i + look_back])\n",
    "                return np.array(X), np.array(Y)\n",
    "\n",
    "            # Set the number of time steps to look back\n",
    "            look_back = 8  # You can adjust this value based on the characteristics of your data\n",
    "\n",
    "            # Create the LSTM dataset\n",
    "            X, Y = create_lstm_dataset(training_data_scaled, look_back)\n",
    "\n",
    "            # Split the data into training and testing sets\n",
    "            train_size = int(len(X) * 0.8)\n",
    "            X_train, X_test = X[:train_size], X[train_size:]\n",
    "            Y_train, Y_test = Y[:train_size], Y[train_size:]\n",
    "\n",
    "            # Build the feature selection model\n",
    "            feature_selection_model = Sequential()\n",
    "            feature_selection_model.add(Dense(units=10, input_dim=len(columns_to_predict), activation='relu'))\n",
    "            feature_selection_model.add(LSTM(units=50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "            feature_selection_model.add(Dense(units=1))  # Assuming you are predicting a single value (MISC FPTS)\n",
    "            feature_selection_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "            # Train the feature selection model\n",
    "            feature_selection_model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_test, Y_test), verbose=0)\n",
    "\n",
    "            # Make predictions on the test set\n",
    "            selected_features = feature_selection_model.predict(X_test)\n",
    "\n",
    "            # Evaluate the model\n",
    "            mse = mean_squared_error(Y_test, selected_features)\n",
    "            print(f'Mean Squared Error {pos}: {mse}')\n",
    "\n",
    "            # Check if the current combination is better than the previous best\n",
    "            if mse < best_performance:\n",
    "                best_performance = mse\n",
    "                best_features = features_to_predict\n",
    "\n",
    "    # Store the optimal features for the current position in the dictionary\n",
    "    optimal_features_dict[pos] = best_features\n",
    "\n",
    "# Print the optimal features for each position\n",
    "for pos, features in optimal_features_dict.items():\n",
    "    print(f\"Optimal features for {pos}: {features}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
