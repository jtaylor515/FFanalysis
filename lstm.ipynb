{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: rb\n",
      "24/24 [==============================] - 0s 923us/step\n",
      "Mean Squared Error rb: 150.154118730924\n",
      "MAE rb: 5.8725374096073395\n",
      "R-squared rb: 0.4079846416110722\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "positions = [\"qb\", \"rb\", \"wr\", \"te\"]\n",
    "positions = [\"rb\"]\n",
    "\n",
    "for pos in positions:\n",
    "    print(\"Position: \" + pos)\n",
    "    # Load your dataset\n",
    "    data = pd.read_csv(\"datasets/weekly_scoring.csv\")\n",
    "\n",
    "    # Preprocessing\n",
    "    data = data[data['POS'] == pos]\n",
    "\n",
    "    # Drop Zero values (bye weeks, injuries)\n",
    "    data = data[data['MISC FPTS'] != 0]\n",
    "    weights = data['WEIGHT']  \n",
    "\n",
    "    \n",
    "    # Instead of dropping zero values, substitute them with the mean (including zeroes) for everyone\n",
    "    # column_to_replace = 'MISC FPTS'\n",
    "    # mean_value = data[column_to_replace].mean()\n",
    "    # data[column_to_replace] = data[column_to_replace].replace(0, mean_value)\n",
    "    \n",
    "    # Replace zero values with the mean specific to each player\n",
    "    # player_means = data.groupby('PLAYER', group_keys=True)[column_to_replace].max()\n",
    "    # data[column_to_replace] = data.groupby('PLAYER')[column_to_replace].apply(lambda x: x.replace(0, x.mean()))\n",
    "\n",
    "    if(pos == 'qb'):\n",
    "        # Define the list of variables to predict\n",
    "        # columns_to_predict = ['PASSING CMP', 'PASSING ATT', 'PASSING PCT', 'PASSING YDS', 'PASSING Y/A', 'PASSING TD', 'PASSING INT',\n",
    "        # 'PASSING SACKS', 'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'MISC FL', 'WEEK', 'AVG_FPTS', 'MAX_FPTS', 'MIN_FPTS', 'VAR_FPTS']\n",
    "        columns_to_predict = ['MISC FPTS', 'AVG_FPTS']\n",
    "        # # Drop Zero values (bye weeks, injuries)\n",
    "        # data = data[data['MISC FPTS'] != 0]\n",
    "        look_back = 15\n",
    "    if(pos == 'rb'):\n",
    "        # columns_to_predict = ['RECEIVING REC', 'RECEIVING TGT', 'RECEIVING YDS', 'RECEIVING Y/R',\n",
    "        # 'RECEIVING TD', 'RUSHING Y/A', 'RUSHING LG',\n",
    "        # 'RUSHING 20+', 'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'MISC FL', 'AVG_FPTS', 'MAX_FPTS', 'VAR_FPTS']\n",
    "        columns_to_predict = ['MISC FPTS', 'RUSHING YDS', 'RUSHING TD', 'RECEIVING YDS', 'RECEIVING TD']\n",
    "        # # Replace zero values with the mean specific to each player\n",
    "        # player_means = data.groupby('PLAYER', group_keys=True)[column_to_replace].max()\n",
    "        # data[column_to_replace] = data.groupby('PLAYER')[column_to_replace].apply(lambda x: x.replace(0, x.mean()))\n",
    "        look_back = 16\n",
    "    if(pos == 'wr'):\n",
    "        # columns_to_predict = ['RECEIVING REC', 'RECEIVING TGT', 'RECEIVING YDS', 'RECEIVING Y/R',\n",
    "        # 'RECEIVING TD', 'RECEIVING LG', 'RECEIVING 20+',\n",
    "        # 'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'MISC FL', 'MISC FPTS', 'WEEK', 'AVG_FPTS', 'MAX_FPTS', 'MIN_FPTS', 'VAR_FPTS']\n",
    "        columns_to_predict = ['MISC FPTS', 'AVG_FPTS', 'RECEIVING YDS', 'RECEIVING TD']\n",
    "        # # Replace zero values with the mean specific to each player\n",
    "        # player_means = data.groupby('PLAYER', group_keys=True)[column_to_replace].max()\n",
    "        # data[column_to_replace] = data.groupby('PLAYER')[column_to_replace].apply(lambda x: x.replace(0, x.mean()))\n",
    "        look_back = 14\n",
    "    if(pos == 'te'):\n",
    "        # columns_to_predict = ['RECEIVING REC', 'RECEIVING TGT', 'RECEIVING YDS', 'RECEIVING Y/R',\n",
    "        # 'RECEIVING TD', 'RECEIVING LG', 'RECEIVING 20+',\n",
    "        # 'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'MISC FL', 'MISC FPTS', 'WEEK', 'AVG_FPTS', 'MAX_FPTS', 'MIN_FPTS', 'VAR_FPTS']\n",
    "        columns_to_predict = ['MISC FPTS', 'AVG_FPTS']\n",
    "        # # Replace zero values with the mean specific to each player\n",
    "        # player_means = data.groupby('PLAYER', group_keys=True)[column_to_replace].max()\n",
    "        # data[column_to_replace] = data.groupby('PLAYER')[column_to_replace].apply(lambda x: x.replace(0, x.mean()))\n",
    "        look_back = 20\n",
    "\n",
    "\n",
    "    # Sort the data by the date column\n",
    "    date_column = \"CONTINUOUS_DATE\"\n",
    "    data[date_column] = pd.to_datetime(data[date_column])\n",
    "    data = data.sort_values(by=date_column)\n",
    "\n",
    "    # Extract the relevant columns for training\n",
    "    training_data = data[columns_to_predict].values\n",
    "\n",
    "    # Impute missing values for training_data\n",
    "    imputer = SimpleImputer(strategy='mean')  # You can change the strategy as needed\n",
    "    training_data = imputer.fit_transform(training_data)\n",
    "    # training_data[np.isnan(training_data)] = 0\n",
    "\n",
    "    # Normalize the data using Min-Max scaling\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    training_data_scaled = scaler.fit_transform(training_data)\n",
    "\n",
    "    # Define a function to create LSTM datasets\n",
    "    def create_lstm_dataset(dataset, look_back=1):\n",
    "        X, Y = [], []\n",
    "        for i in range(len(dataset) - look_back):\n",
    "            X.append(dataset[i:(i + look_back)])\n",
    "            Y.append(dataset[i + look_back])\n",
    "        return np.array(X), np.array(Y)\n",
    "\n",
    "    # Create the LSTM dataset\n",
    "    X, Y = create_lstm_dataset(training_data_scaled, look_back)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    Y_train, Y_test = Y[:train_size], Y[train_size:]    \n",
    "    # Reshape the input data for LSTM (samples, time steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], look_back, X_train.shape[2]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], look_back, X_test.shape[2]))\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(units=len(columns_to_predict)))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_test, Y_test), verbose=0)\n",
    "\n",
    "    # print(\"LSTM Model Summary:\")\n",
    "    # model.summary()\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Rescale the predictions to the original scale\n",
    "    predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "    Y_test_rescaled = scaler.inverse_transform(Y_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(Y_test_rescaled, predictions_rescaled)\n",
    "    print(f'Mean Squared Error {pos}: {mse}')\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    # rmse = np.sqrt(mean_squared_error(Y_test_rescaled, predictions_rescaled))\n",
    "    # print(f\"RMSE {pos}: {rmse}\")\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(Y_test_rescaled, predictions_rescaled)\n",
    "    print(f\"MAE {pos}: {mae}\")\n",
    "\n",
    "    # R-squared\n",
    "    r_squared = r2_score(Y_test_rescaled, predictions_rescaled)\n",
    "    print(f\"R-squared {pos}: {r_squared}\")\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    results_list = []\n",
    "\n",
    "    # Create a DataFrame with 'PLAYER' and predicted values\n",
    "    result_df = pd.DataFrame({'PLAYER': data['PLAYER'].iloc[train_size + look_back:], 'Predicted_FPTS': predictions_rescaled[:, 0]})\n",
    "\n",
    "    # Group by 'PLAYER' and calculate the average predicted FPTS\n",
    "    result_df = result_df.groupby('PLAYER').mean().reset_index()\n",
    "    result_df = result_df.sort_values(by='Predicted_FPTS', ascending=False)\n",
    "\n",
    "    # Add the 'TEAM' column if needed (replace with your own logic)\n",
    "    pattern = r'\\((.*?)\\)'\n",
    "    result_df['TEAM'] = result_df['PLAYER'].apply(lambda x: re.search(pattern, x).group(1) if re.search(pattern, x) else pd.NA)\n",
    "\n",
    "    # # Keep only the first unique occurrence of any value in the 'TEAM' column\n",
    "    # result_df = result_df.drop_duplicates(subset='TEAM')\n",
    "\n",
    "    # Append the results to the list\n",
    "    results_list.append(result_df)\n",
    "\n",
    "    # Combine the results from all folds\n",
    "    final_results_df = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "    # Remove any player with the team equal to 'FA'\n",
    "    final_results_df = final_results_df.query(\"TEAM != 'FA'\")\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    file_name = f\"predictions/LSTM_predictions_{pos}.csv\"\n",
    "    final_results_df.to_csv(file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
