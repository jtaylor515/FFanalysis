{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: qb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/rhs7cnfj66l4p8v_yrkw8n4m0000gn/T/ipykernel_43817/3122573590.py:33: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  data[column_to_replace] = data.groupby('PLAYER')[column_to_replace].apply(lambda x: x.replace(0, x.mean()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Model Summary:\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_30 (LSTM)              (None, 50)                10400     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10451 (40.82 KB)\n",
      "Trainable params: 10451 (40.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "17/17 [==============================] - 0s 737us/step\n",
      "Mean Squared Error qb: 36.99641288841832\n",
      "MAE qb: 4.8990636305432735\n",
      "R-squared qb: 0.4631166975152198\n",
      "Position: rb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/rhs7cnfj66l4p8v_yrkw8n4m0000gn/T/ipykernel_43817/3122573590.py:33: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  data[column_to_replace] = data.groupby('PLAYER')[column_to_replace].apply(lambda x: x.replace(0, x.mean()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Model Summary:\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_31 (LSTM)              (None, 50)                10400     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10451 (40.82 KB)\n",
      "Trainable params: 10451 (40.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "38/38 [==============================] - 0s 663us/step\n",
      "Mean Squared Error rb: 9.994804455329751\n",
      "MAE rb: 1.909953409441552\n",
      "R-squared rb: 0.6122253511854656\n",
      "Position: wr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/rhs7cnfj66l4p8v_yrkw8n4m0000gn/T/ipykernel_43817/3122573590.py:33: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  data[column_to_replace] = data.groupby('PLAYER')[column_to_replace].apply(lambda x: x.replace(0, x.mean()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Model Summary:\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_32 (LSTM)              (None, 50)                10400     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10451 (40.82 KB)\n",
      "Trainable params: 10451 (40.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "56/56 [==============================] - 0s 582us/step\n",
      "Mean Squared Error wr: 4.959956822730139\n",
      "MAE wr: 1.330206970544938\n",
      "R-squared wr: 0.7235945921870499\n",
      "Position: te\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/rhs7cnfj66l4p8v_yrkw8n4m0000gn/T/ipykernel_43817/3122573590.py:33: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  data[column_to_replace] = data.groupby('PLAYER')[column_to_replace].apply(lambda x: x.replace(0, x.mean()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Model Summary:\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_33 (LSTM)              (None, 50)                10400     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10451 (40.82 KB)\n",
      "Trainable params: 10451 (40.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "30/30 [==============================] - 0s 603us/step\n",
      "Mean Squared Error te: 4.368937849548338\n",
      "MAE te: 1.3072442640440018\n",
      "R-squared te: 0.48637716685745447\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "positions = [\"qb\", \"rb\", \"wr\", \"te\"]\n",
    "# positions = [\"rb\"]\n",
    "\n",
    "for pos in positions:\n",
    "    print(\"Position: \" + pos)\n",
    "    # Load your dataset\n",
    "    data = pd.read_csv(\"datasets/weekly_scoring.csv\")\n",
    "\n",
    "    # Preprocessing\n",
    "    data = data[data['POS'] == pos]\n",
    "    weights = data['WEIGHT']  \n",
    "    # Drop Zero values (bye weeks, injuries)\n",
    "    data = data[data['MISC FPTS'] != 0]\n",
    "    \n",
    "    # Instead of dropping zero values, substitute them with the mean (including zeroes) for the player\n",
    "    column_to_replace = 'MISC FPTS'\n",
    "    # mean_value = data[column_to_replace].mean()\n",
    "    # data[column_to_replace] = data[column_to_replace].replace(0, mean_value)\n",
    "    \n",
    "    # Replace zero values with the mean specific to each player\n",
    "    # player_means = data.groupby('PLAYER', group_keys=True)[column_to_replace].max()\n",
    "    # data[column_to_replace] = data.groupby('PLAYER')[column_to_replace].apply(lambda x: x.replace(0, x.mean()))\n",
    "\n",
    "    if(pos == 'qb'):\n",
    "        # Define the list of variables to predict\n",
    "        # columns_to_predict = ['PASSING CMP', 'PASSING ATT', 'PASSING PCT', 'PASSING YDS', 'PASSING Y/A', 'PASSING TD', 'PASSING INT',\n",
    "        # 'PASSING SACKS', 'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'MISC FL', 'WEEK', 'AVG_FPTS', 'MAX_FPTS', 'MIN_FPTS', 'VAR_FPTS']\n",
    "        columns_to_predict = ['MISC FPTS']\n",
    "    if(pos == 'rb'):\n",
    "        # columns_to_predict = ['RECEIVING REC', 'RECEIVING TGT', 'RECEIVING YDS', 'RECEIVING Y/R',\n",
    "        # 'RECEIVING TD', 'RUSHING Y/A', 'RUSHING LG',\n",
    "        # 'RUSHING 20+', 'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'MISC FL', 'AVG_FPTS', 'MAX_FPTS', 'VAR_FPTS']\n",
    "        columns_to_predict = ['MISC FPTS']\n",
    "    if(pos == 'wr'):\n",
    "        # columns_to_predict = ['RECEIVING REC', 'RECEIVING TGT', 'RECEIVING YDS', 'RECEIVING Y/R',\n",
    "        # 'RECEIVING TD', 'RECEIVING LG', 'RECEIVING 20+',\n",
    "        # 'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'MISC FL', 'MISC FPTS', 'WEEK', 'AVG_FPTS', 'MAX_FPTS', 'MIN_FPTS', 'VAR_FPTS']\n",
    "        columns_to_predict = ['MISC FPTS']\n",
    "    if(pos == 'te'):\n",
    "        # columns_to_predict = ['RECEIVING REC', 'RECEIVING TGT', 'RECEIVING YDS', 'RECEIVING Y/R',\n",
    "        # 'RECEIVING TD', 'RECEIVING LG', 'RECEIVING 20+',\n",
    "        # 'RUSHING ATT', 'RUSHING YDS', 'RUSHING TD', 'MISC FL', 'MISC FPTS', 'WEEK', 'AVG_FPTS', 'MAX_FPTS', 'MIN_FPTS', 'VAR_FPTS']\n",
    "        columns_to_predict = ['MISC FPTS']\n",
    "\n",
    "\n",
    "    # Sort the data by the date column\n",
    "    date_column = \"CONTINUOUS_DATE\"\n",
    "    data[date_column] = pd.to_datetime(data[date_column])\n",
    "    data = data.sort_values(by=date_column)\n",
    "\n",
    "    # Extract the relevant columns for training\n",
    "    training_data = data[columns_to_predict].values\n",
    "\n",
    "    # Impute missing values for training_data\n",
    "    imputer = SimpleImputer(strategy='mean')  # You can change the strategy as needed\n",
    "    training_data = imputer.fit_transform(training_data)\n",
    "    # training_data[np.isnan(training_data)] = 0\n",
    "\n",
    "    # Normalize the data using Min-Max scaling\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    training_data_scaled = scaler.fit_transform(training_data)\n",
    "\n",
    "    # Define a function to create LSTM datasets\n",
    "    def create_lstm_dataset(dataset, look_back=1):\n",
    "        X, Y = [], []\n",
    "        for i in range(len(dataset) - look_back):\n",
    "            X.append(dataset[i:(i + look_back)])\n",
    "            Y.append(dataset[i + look_back])\n",
    "        return np.array(X), np.array(Y)\n",
    "\n",
    "    # Set the number of time steps to look back\n",
    "    look_back = 4  # You can adjust this value based on the characteristics of your data\n",
    "\n",
    "    # Create the LSTM dataset\n",
    "    X, Y = create_lstm_dataset(training_data_scaled, look_back)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    Y_train, Y_test = Y[:train_size], Y[train_size:]    \n",
    "    # Reshape the input data for LSTM (samples, time steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], look_back, X_train.shape[2]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], look_back, X_test.shape[2]))\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(units=len(columns_to_predict)))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_test, Y_test), verbose=0)\n",
    "\n",
    "    print(\"LSTM Model Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Rescale the predictions to the original scale\n",
    "    predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "    Y_test_rescaled = scaler.inverse_transform(Y_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(Y_test_rescaled, predictions_rescaled)\n",
    "    print(f'Mean Squared Error {pos}: {mse}')\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    # rmse = np.sqrt(mean_squared_error(Y_test_rescaled, predictions_rescaled))\n",
    "    # print(f\"RMSE {pos}: {rmse}\")\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(Y_test_rescaled, predictions_rescaled)\n",
    "    print(f\"MAE {pos}: {mae}\")\n",
    "\n",
    "    # R-squared\n",
    "    r_squared = r2_score(Y_test_rescaled, predictions_rescaled)\n",
    "    print(f\"R-squared {pos}: {r_squared}\")\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    results_list = []\n",
    "\n",
    "    # Create a DataFrame with 'PLAYER' and predicted values\n",
    "    result_df = pd.DataFrame({'PLAYER': data['PLAYER'].iloc[train_size + look_back:], 'Predicted_FPTS': predictions_rescaled[:, 0]})\n",
    "\n",
    "    # Group by 'PLAYER' and calculate the average predicted FPTS\n",
    "    result_df = result_df.groupby('PLAYER').mean().reset_index()\n",
    "    result_df = result_df.sort_values(by='Predicted_FPTS', ascending=False)\n",
    "\n",
    "    # Add the 'TEAM' column if needed (replace with your own logic)\n",
    "    pattern = r'\\((.*?)\\)'\n",
    "    result_df['TEAM'] = result_df['PLAYER'].apply(lambda x: re.search(pattern, x).group(1) if re.search(pattern, x) else pd.NA)\n",
    "\n",
    "    # # Keep only the first unique occurrence of any value in the 'TEAM' column\n",
    "    # result_df = result_df.drop_duplicates(subset='TEAM')\n",
    "\n",
    "    # Append the results to the list\n",
    "    results_list.append(result_df)\n",
    "\n",
    "    # Combine the results from all folds\n",
    "    final_results_df = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "    # Remove any player with the team equal to 'FA'\n",
    "    final_results_df = final_results_df.query(\"TEAM != 'FA'\")\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    file_name = f\"predictions/LSTM_predictions_{pos}.csv\"\n",
    "    final_results_df.to_csv(file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
